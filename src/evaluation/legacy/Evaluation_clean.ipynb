{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from pandas.core.common import flatten\n",
    "import pickle \n",
    "import os\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import original dataset for random forest\n",
    "df_obs=pd.read_csv('../data/df_20210510.csv',index_col=0)\n",
    "df_obs=df_obs.dropna()\n",
    "df_obs=df_obs[['date','GPP_NT_VUT_REF']]\n",
    "df_obs=df_obs[df_obs.index!='CN-Cng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = pickle.load(open('RF_predictions_d10_n200.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN = pickle.load(open('pred_dnn.pkl', 'rb'))\n",
    "LSTM= pickle.load(open('pred_lstm.pkl', 'rb'))\n",
    "target= pickle.load(open('target_gpp.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['LSTM']=LSTM['pred']\n",
    "target['DNN']=list(flatten(DNN['preds']))\n",
    "df_obs['RF']=list(flatten(RF['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready=target\n",
    "df_ready_rf=df_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites=df_ready.index.unique()\n",
    "df_ready['date'] = pd.to_datetime(df_ready.date)\n",
    "df_ready['month'] = df_ready.date.map(lambda x: x.month)\n",
    "df_ready['day'] = df_ready.date.map(lambda x: x.day)\n",
    "df_ready['year'] = df_ready.date.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready_rf['date'] = pd.to_datetime(df_ready_rf.date)\n",
    "df_ready_rf['month'] = df_ready_rf.date.map(lambda x: x.month)\n",
    "df_ready_rf['day'] = df_ready_rf.date.map(lambda x: x.day)\n",
    "df_ready_rf['year'] = df_ready_rf.date.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpp = [df_ready[df_ready.index == site]['GPP_NT_VUT_REF'] for site in sites] \n",
    "df_gpp = [(df_gpp[i]-df_gpp[i].mean())/df_gpp[i].std() for i in range(len(df_gpp))]\n",
    "df_ready['GPP']=list(np.concatenate(df_gpp).flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 for random forest\n",
    "r2_rf=[]\n",
    "for site in sites:\n",
    "    df=df_ready_rf[df_ready_rf.index==site]\n",
    "    df=df.dropna()\n",
    "    r2_rf.append(r2_score(df['GPP_NT_VUT_REF'],df['RF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=pd.DataFrame({\"RF\": r2_rf,\n",
    "                   \"sites\": sites})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_csv(\"rf_R2_n200_d10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for LSTM anomalies extreme condition\n",
    "r2_norm = []\n",
    "r2_uq = []\n",
    "r2_lq = []\n",
    "month = []\n",
    "for site in sites:\n",
    "    data = df_ready[df_ready.index == site]\n",
    "    ms = data.groupby(['month','day']).mean()['GPP_NT_VUT_REF'].values\n",
    "    data['day_year'] = data['date'].map(lambda x: x.timetuple().tm_yday)\n",
    "    if(ms.shape[0] < 366 ): continue\n",
    "    anomalies = data.apply(lambda x: x['GPP_NT_VUT_REF'] - ms[x['day_year'] -1], axis=1)\n",
    "    uq = anomalies.quantile(q=0.95)\n",
    "    lq = anomalies.quantile(q=0.05)\n",
    "    gpp_uq = data['GPP'][anomalies >= uq]\n",
    "    pred_uq = data['LSTM'][anomalies >= uq]\n",
    "    gpp_lq = data['GPP'][anomalies <= lq]\n",
    "    pred_lq = data['LSTM'][anomalies <= lq]\n",
    "    norm = np.logical_and((anomalies > lq).values, (anomalies < uq ).values)\n",
    "    gpp_norm = data['GPP'][norm]\n",
    "    pred_norm = data['LSTM'][norm]\n",
    "    monthly_gpp = data.groupby([ 'month']).mean()['GPP'].values\n",
    "    monthly_pred = data.groupby([ 'month']).mean()['LSTM'].values\n",
    "    month.append(mean_squared_error(monthly_gpp, monthly_pred, squared=False))\n",
    "    r2_norm.append(np.mean(pred_norm-gpp_norm))\n",
    "    r2_uq.append(np.mean(pred_uq-gpp_uq))\n",
    "    r2_lq.append(np.mean(pred_lq-gpp_lq))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"normal\": r2_norm,\n",
    "                   \"upper_quantile\": r2_uq,\n",
    "                   \"lower_quantile\": r2_lq})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"lstm_extreme_condition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for LSTM different time scale\n",
    "monthly=[]\n",
    "yearly=[]\n",
    "r2_monthly=[]\n",
    "r2_yearly=[]\n",
    "r2_daily=[]\n",
    "for site in sites:\n",
    "    data = df_ready[df_ready.index == site]\n",
    "    data=data.dropna()\n",
    "    m= data.groupby(['month','year']).mean()['GPP'].values # map to month mean \n",
    "    y= data.groupby(['year']).mean()['GPP'].values # map to year mean\n",
    "    m_pred= data.groupby(['month','year']).mean()['LSTM'].values\n",
    "    y_pred= data.groupby(['year']).mean()['LSTM'].values\n",
    "    r2_daily.append(r2_score(data['GPP'],data['LSTM']))\n",
    "    r2_monthly.append(r2_score(m,m_pred))\n",
    "    if(len(y)>8):\n",
    "        r2_yearly.append(r2_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lstm=np.mean(r2_daily)\n",
    "yearly_lstm=np.mean(r2_yearly)\n",
    "monthly_lstm=np.mean(r2_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for DNN extreme conditions\n",
    "r2_norm = []\n",
    "r2_uq = []\n",
    "r2_lq = []\n",
    "month = []\n",
    "for site in sites:\n",
    "    data = df_ready[df_ready.index == site]\n",
    "    ms = data.groupby(['month','day']).mean()['GPP_NT_VUT_REF'].values\n",
    "    data['day_year'] = data['date'].map( lambda x: x.timetuple().tm_yday)\n",
    "    if(ms.shape[0] < 366 ): continue\n",
    "    anomalies = data.apply(lambda x: x['GPP_NT_VUT_REF'] - ms[x['day_year'] -1], axis=1)\n",
    "    uq = anomalies.quantile(q=0.95)\n",
    "    lq = anomalies.quantile(q=0.05)\n",
    "    gpp_uq = data['GPP'][anomalies >= uq]\n",
    "    pred_uq = data['DNN'][anomalies >= uq]\n",
    "    gpp_lq = data['GPP'][anomalies <= lq]\n",
    "    pred_lq = data['DNN'][anomalies <= lq]\n",
    "    norm = np.logical_and((anomalies > lq).values, (anomalies < uq ).values)\n",
    "    gpp_norm = data['GPP'][norm]\n",
    "    pred_norm = data['DNN'][norm]\n",
    "    monthly_gpp = data.groupby([ 'month']).mean()['GPP'].values\n",
    "    monthly_pred = data.groupby([ 'month']).mean()['DNN'].values\n",
    "    month.append(mean_squared_error(monthly_gpp, monthly_pred, squared=False))\n",
    "    r2_norm.append(np.mean(pred_norm-gpp_norm))\n",
    "    r2_uq.append(np.mean(pred_uq-gpp_uq))\n",
    "    r2_lq.append(np.mean(pred_lq-gpp_lq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"normal\": r2_norm,\n",
    "                   \"upper_quantile\": r2_uq,\n",
    "                   \"lower_quantile\": r2_lq})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dnn_extreme_condition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for DNN different time scale\n",
    "monthly=[]\n",
    "yearly=[]\n",
    "r2_monthly=[]\n",
    "r2_yearly=[]\n",
    "r2_daily=[]\n",
    "for site in sites:\n",
    "    data = df_ready[df_ready.index == site]\n",
    "    data=data.dropna()\n",
    "#     ms = data.groupby(['month','day']).mean()['GPP'].values #map to month and days\n",
    "    m= data.groupby(['month','year']).mean()['GPP'].values # map to month mean \n",
    "    y= data.groupby(['year']).mean()['GPP'].values # map to year mean\n",
    "#     ms_pred = data.groupby(['month','day']).mean()['LSTM'].values\n",
    "    m_pred= data.groupby(['month','year']).mean()['DNN'].values\n",
    "    y_pred= data.groupby(['year']).mean()['DNN'].values\n",
    "    r2_daily.append(r2_score(data['GPP'],data['DNN']))\n",
    "    r2_monthly.append(r2_score(m,m_pred))\n",
    "    if(len(y)>8):\n",
    "        r2_yearly.append(r2_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_DNN=np.mean(r2_daily)\n",
    "monthly_DNN=np.mean(r2_monthly)\n",
    "yearly_DNN=np.mean(r2_yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for RF extreme condition\n",
    "r2_norm = []\n",
    "r2_uq = []\n",
    "r2_lq = []\n",
    "month = []\n",
    "for site in sites:\n",
    "    data = df_ready_rf[df_ready_rf.index == site]\n",
    "    ms = data.groupby(['month','day']).mean()['GPP_NT_VUT_REF'].values\n",
    "    data['day_year'] = data['date'].map( lambda x: x.timetuple().tm_yday)\n",
    "    if(ms.shape[0] < 366 ): continue\n",
    "    anomalies = data.apply(lambda x: x['GPP_NT_VUT_REF'] - ms[x['day_year'] -1], axis=1)\n",
    "    uq = anomalies.quantile(q=0.95)\n",
    "    lq = anomalies.quantile(q=0.05)\n",
    "    gpp_uq = data['GPP_NT_VUT_REF'][anomalies >= uq]\n",
    "    pred_uq = data['RF'][anomalies >= uq]\n",
    "    gpp_lq = data['GPP_NT_VUT_REF'][anomalies <= lq]\n",
    "    pred_lq = data['RF'][anomalies <= lq]\n",
    "    norm = np.logical_and((anomalies > lq).values, (anomalies < uq ).values)\n",
    "    gpp_norm = data['GPP_NT_VUT_REF'][norm]\n",
    "    pred_norm = data['RF'][norm]\n",
    "    monthly_gpp = data.groupby(['month']).mean()['GPP_NT_VUT_REF'].values\n",
    "    monthly_pred = data.groupby(['month']).mean()['RF'].values\n",
    "    month.append(mean_squared_error(monthly_gpp, monthly_pred, squared=False))\n",
    "    r2_norm.append(np.mean(pred_norm-gpp_norm))\n",
    "    r2_uq.append(np.mean(pred_uq-gpp_uq))\n",
    "    r2_lq.append(np.mean(pred_lq-gpp_lq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"normal\": r2_norm,\n",
    "                   \"upper_quantile\": r2_uq,\n",
    "                   \"lower_quantile\": r2_lq})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"rf_extreme_condition_n200_d10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for RF different time scale\n",
    "monthly=[]\n",
    "yearly=[]\n",
    "r2_monthly=[]\n",
    "r2_yearly=[]\n",
    "r2_daily=[]\n",
    "for site in sites:\n",
    "    data = df_ready_rf[df_ready_rf.index == site]\n",
    "    data=data.dropna()\n",
    "    m= data.groupby(['month','year']).mean()['GPP_NT_VUT_REF'].values # map to month mean \n",
    "    y= data.groupby(['year']).mean()['GPP_NT_VUT_REF'].values # map to year mean\n",
    "    m_pred= data.groupby(['month','year']).mean()['RF'].values\n",
    "    y_pred= data.groupby(['year']).mean()['RF'].values\n",
    "    r2_daily.append(r2_score(data['GPP_NT_VUT_REF'],data['RF']))\n",
    "    r2_monthly.append(r2_score(m,m_pred))\n",
    "    if(len(y)>8):\n",
    "        r2_yearly.append(r2_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_rf=np.mean(r2_daily)\n",
    "monthly_rf=np.mean(r2_monthly)\n",
    "yearly_rf=np.mean(r2_yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont run aggregation alone, need to run the corresponding model first \n",
    "#as the array are named the same \n",
    "#this is outputing the file for the aggregations\n",
    "d_out=pd.DataFrame({\"daily_rf\":daily_rf,\"monthly_rf\":monthly_rf,\"yearly_rf\":yearly_rf,\n",
    "      \"daily_DNN\":daily_DNN,\"monthly_DNN\":monthly_DNN,\"yearly_DNN\":yearly_DNN,\n",
    "      \"daily_lstm\":daily_lstm,\"monthly_lstm\":monthly_lstm,\"yearly_lstm\":yearly_lstm}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out.to_csv('aggregating to different time scales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
