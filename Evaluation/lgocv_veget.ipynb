{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import operator\n",
    "from model.model import Model\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "from preprocess import normalize\n",
    "import torch.nn.functional as F\n",
    "data = pd.read_csv('utils/df_imputed.csv', index_col=0)\n",
    "data = data.drop(columns='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('../data/df_20210510.csv', index_col=0)['GPP_NT_VUT_REF']\n",
    "raw = raw[raw.index != 'CN-Cng']\n",
    "sites = raw.index.unique()\n",
    "\n",
    "masks = []\n",
    "for s in sites:\n",
    "    mask = raw[raw.index == s].isna().values\n",
    "    masks.append(list(map(operator.not_, mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_columns=['classid','igbp_land_use']\n",
    "sites = data.index.unique()\n",
    "meta_data = pd.get_dummies(data[meta_columns])\n",
    "sensor_data = data.drop(columns=['classid', 'plant_functional_type', 'koeppen_code','igbp_land_use', 'GPP_NT_VUT_REF'])\n",
    "\n",
    "# Batch by site\n",
    "df_sensor = [normalize(sensor_data[sensor_data.index == site]) for site in sites if sensor_data[sensor_data.index == site].size != 0 ]\n",
    "df_meta = [meta_data[meta_data.index == site] for site in sites if meta_data[meta_data.index == site].size != 0]\n",
    "df_gpp = [data[data.index == site]['GPP_NT_VUT_REF'] for site in sites if data[data.index == site].size != 0]   \n",
    "df_gpp = [(df_gpp[i]-df_gpp[i].mean())/df_gpp[i].std() for i in range(len(df_gpp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = ['DBF', 'ENF', 'GRA', 'MF'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataframes by veg type\n",
    "dbf_sites = []\n",
    "enf_sites = []\n",
    "gra_sites = []\n",
    "mf_sites  = []\n",
    "for i in range(len(df_sensor)):\n",
    "    if df_meta[i]['classid_DBF'][0] == 1:\n",
    "        dbf_sites.append(i)\n",
    "    elif df_meta[i]['classid_ENF'][0] == 1:\n",
    "        enf_sites.append(i)\n",
    "    elif df_meta[i]['classid_GRA'][0] == 1:\n",
    "        gra_sites.append(i)\n",
    "    elif df_meta[i]['classid_MF'][0] == 1:\n",
    "        mf_sites.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sites_in.append(train_sites[0])\n",
    "# train_sites.remove(train_sites[0])\n",
    "# test_sites_in.append(train_sites[-1])\n",
    "# train_sites.remove(train_sites[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model parameter\n",
    "DEVICE = \"cuda:7\"\n",
    "INPUT_FEATURES = len(df_sensor[0].columns) \n",
    "HIDDEN_DIM = 256\n",
    "CONDITIONAL_FEATURES = len(df_meta[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sites = deepcopy(dbf_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 26, 30, 34, 43, 45, 50, 51]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(x_test,y_test,conditional_test, sites):\n",
    "    i = 0\n",
    "    r2 = 0\n",
    "    for (x, y,conditional) in zip(x_test, y_test, conditional_test):\n",
    "        x = torch.FloatTensor(x).to(DEVICE)\n",
    "        y = torch.FloatTensor(y).to(DEVICE)\n",
    "        c = torch.FloatTensor(conditional).to(DEVICE)\n",
    "        y_pred = model(x, c)\n",
    "        test_loss = F.mse_loss( y_pred, y)\n",
    "        r2 += r2_score(y_true=y.detach().cpu().numpy()[masks[sites[i]]], y_pred=y_pred.detach().cpu().numpy()[masks[sites[i]]])\n",
    "        i += 1\n",
    "    r2 /= i\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias(x_test,y_test,conditional_test, sites):\n",
    "    i = 0\n",
    "    bias = []\n",
    "    for (x, y,conditional) in zip(x_test, y_test, conditional_test):\n",
    "        x = torch.FloatTensor(x).to(DEVICE)\n",
    "        y = torch.FloatTensor(y).to(DEVICE)\n",
    "        c = torch.FloatTensor(conditional).to(DEVICE)\n",
    "        y_pred = model(x, c)\n",
    "        bias.append((y_pred - y).detach().cpu().numpy())\n",
    "        i += 1\n",
    "    \n",
    "    return np.concatenate(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 1/9 [03:37<28:56, 217.11s/it]"
     ]
    }
   ],
   "source": [
    "# This cell computes the bias by vegetation types. \n",
    "# We divided the training one into two parts, namely train_sites and test_sites_in by leave-one-out method.\n",
    "# We also test on all other types that are not used for training. \n",
    "# Need to note the dataframe in outter loop also in need of changing when one want to train on other vegetation types. \n",
    "\n",
    "all_bias_gra = []\n",
    "all_bias_enf = []\n",
    "all_bias_dbf = []\n",
    "all_bias_mf = []\n",
    "\n",
    "for k in tqdm(range(len(dbf_sites))):\n",
    "    \n",
    "    # define model\n",
    "    model = Model(INPUT_FEATURES, CONDITIONAL_FEATURES, HIDDEN_DIM,0, 1).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    # define data \n",
    "    train_sites = deepcopy(dbf_sites)\n",
    "    train_sites.remove(dbf_sites[k])\n",
    "    test_sites_in = [dbf_sites[k]]\n",
    "    \n",
    "    x_train = [df_sensor[i].values for i in train_sites]\n",
    "    y_train = [df_gpp[i].values.reshape(-1,1) for i in train_sites]\n",
    "    conditional_train = [df_meta[i].values for i in train_sites]\n",
    "\n",
    "    x_test_gra = [df_sensor[i].values for i in gra_sites]\n",
    "    y_test_gra = [df_gpp[i].values.reshape(-1,1) for i in gra_sites]\n",
    "    conditional_test_gra = [df_meta[i].values for i in gra_sites]\n",
    "\n",
    "    x_test_enf = [df_sensor[i].values for i in enf_sites]\n",
    "    y_test_enf = [df_gpp[i].values.reshape(-1,1) for i in enf_sites]\n",
    "    conditional_test_enf = [df_meta[i].values for i in enf_sites]\n",
    "\n",
    "    x_test_mf = [df_sensor[i].values for i in mf_sites]\n",
    "    y_test_mf = [df_gpp[i].values.reshape(-1,1) for i in mf_sites]\n",
    "    conditional_test_mf = [df_meta[i].values for i in mf_sites]\n",
    "\n",
    "\n",
    "    x_test_dbf = [df_sensor[i].values for i in test_sites_in]\n",
    "    y_test_dbf = [df_gpp[i].values.reshape(-1,1) for i in test_sites_in]\n",
    "    conditional_test_dbf = [df_meta[i].values for i in test_sites_in]\n",
    "\n",
    "\n",
    "    best_r2 = 0\n",
    "    for epoch in range(25):\n",
    "        train_loss = 0.0\n",
    "        train_r2 = 0.0\n",
    "        model.train()\n",
    "        for (x, y, conditional) in zip(x_train, y_train, conditional_train):\n",
    "            x = torch.FloatTensor(x).to(DEVICE)\n",
    "            y = torch.FloatTensor(y).to(DEVICE)\n",
    "            c = torch.FloatTensor(conditional).to(DEVICE)\n",
    "            y_pred = model(x, c)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.mse_loss( y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_r2 += r2_score(y_true=y.detach().cpu().numpy(), y_pred=y_pred.detach().cpu().numpy())\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "                r2_gra = validate(x_test_gra, y_test_gra, conditional_test_gra, gra_sites)\n",
    "                r2_enf = validate(x_test_enf, y_test_enf, conditional_test_enf, enf_sites)\n",
    "                r2_mf = validate(x_test_mf, y_test_mf, conditional_test_mf, mf_sites)\n",
    "                r2_dbf = validate(x_test_dbf, y_test_dbf, conditional_test_dbf, test_sites_in)\n",
    "                if r2_dbf > best_r2:\n",
    "                    best_r2 = r2_dbf\n",
    "                    bias_gra = compute_bias(x_test_gra, y_test_gra, conditional_test_gra, gra_sites)\n",
    "                    bias_enf = compute_bias(x_test_enf, y_test_enf, conditional_test_enf, enf_sites)\n",
    "                    bias_mf = compute_bias(x_test_mf, y_test_mf, conditional_test_mf, mf_sites)\n",
    "                    bias_dbf = compute_bias(x_test_dbf, y_test_dbf, conditional_test_dbf, test_sites_in)        \n",
    "    all_bias_dbf.append(bias_dbf)\n",
    "    all_bias_enf.append(bias_enf)\n",
    "    all_bias_mf.append(bias_mf)\n",
    "    all_bias_gra.append(bias_gra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34335, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.concatenate(bias_gra).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6882744 ],\n",
       "       [-0.5787851 ],\n",
       "       [-0.99682605],\n",
       "       ...,\n",
       "       [-0.02996317],\n",
       "       [ 0.10080877],\n",
       "       [ 0.26739553]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bias_gra[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
